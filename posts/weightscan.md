---
title: 'Weightscan: squeezing transformer hidden states into 3d'
excerpt: "What is the shape of a large language model's thoughts?"
date: '2024-04-28'
author:
  name: Riley Stewart
---
Currently, the inner operation of transformer-based large language models has yet to be fully understood by science. The era of frontier models demands a pioneering spirit to navigate. Thus, despite not being familiar with modern machine learning techniques, I started hacking on a script to somehow visualize the layerwise transformation of the hidden states of a large language model small enough to run on my 3060. 

It started when I saw a post on Reddit for a project called [NeuralFlow](https://github.com/valine/NeuralFlow), which was a script you could run to get a visualization of the activations of a LLM. The author was using it to help with fine-tuning open source chat models, where the visualization conveyed when a model was on the edge of stability and chaos. All it takes is a couple hundred lines of Python (which I am familiar with) and torch/numpy/hf transformers matrix munging. 

![NeuralFlow](/assets/blog/weightscan/neuralflow.png)
<figcaption>The visualization provided by NeuralFlow</figcaption>

For me, what I want a visualization for is to help understand the geometry of the latent space of the model and how it evolves in the layerwise transformation while running inference. Recently, on a bit of a lark, I read the book "When Time Breaks Down: The Three-Dimensional Dynamics of Electrochemical Waves and Cardiac Arrhythmias" by Arthur Winfree. Though written in 1987, it contained a lot of fascinating ideas about how singularities and the topology of scroll waves in active media like heart tissue and the [Belousov-Zhabotinsky reaction](https://en.wikipedia.org/wiki/Belousov%E2%80%93Zhabotinsky_reaction) determined their dynamics (in the latter case, whether they fan out in concentric circles or spirals is determined by whether the number of singularities is even or odd). "Singularities", while being a bit of an overloaded term, links a lot of interesting things beyond trite futurism. Going back to large language models, it quickly brings to mind [Singular Learning Theory](https://arxiv.org/abs/2010.11560), whose singularities are more related to the information geometry of a learning model. 

Is there a way to surface those singularities into a medium similar to the ones Winfree studied? I would hope to eventually know the answer to this, though I'm afraid my nascent experimentation here didn't. First, I simply passed the layer outputs of the model into UMAP, down to 2 dimensions. To visualize geometry, I mapped those to a density plot, and wrote out an mp4. Success? Well, there will still a lot of problems. There was some interesting stuff going on, but obviously not enough for what was happening in the model (I started off using Phi 2, but eventually ended up with StableLM2). 

![EarlyHiddenStates](/assets/blog/weightscan/hidden_states.mp4)
<figcaption>Murky yet intriguing already.</figcaption>

I realized then a consequence of a very basic fact about transformer-based LLMs - the dimension of the hidden state is proportional to the sequence length, as each token in the input sequence gets embedded and positionally encoded. This isn't intuitive, as the output is only one token, but for attention to work as it does it needs to operate on the sequence as a whole. [Recent papers](https://arxiv.org/abs/2402.14848) have shown how even otherwise blank tokens can determine the performance of the activation as a whole. So, I wanted to normalize the hidden states, from the sequence length to a large constant that would represent that many particles. To do this, I built a simple autoencoder with the help of ChatGPT, which was trained on the hidden states of the activation (of dimension sequenceLength x hiddenSize) to output 1024 16-dimensional vectors, which I could then pass into UMAP as before and get 1024 2d points. In 2d, however, it isn't easy or often possible to see the geometry of the underlying data - too much is lost. 3d, however, offers an additional degree of freedom which is crucial to displaying geometric information, while also being the familiar dimension of everyday life. First I changed my code to have UMAP output 3d points and flatten them in my visualization, which was itself intriguing enough to begin building a 3d viewer.

Though there are some Python libraries to do 3d visualizations in, I wasn't familiar with any, and attempts to use open3d e.g. were met with failure. So, I returned to the web to build a visualization using Three.js. I didn't want to have to have a build process or host a server to get the points data from the Python script to the web page, so I just made it a template that I could write the data in from the script, which worked fine. Once again I used ChatGPT to help with the Three.js code - there is nowhere it shines better than to help getting started with a new thing, instead of wading into the million vacuous tutorials that exist and hoping you find a good one, or relying on the design of the library documentation. After some tweaking, I got a nice 3d visualization that let me see the evolution of the geometry of the hidden state of the model (through the lens of my autoencoder and UMAP, of course). 

Unfortunately it takes a bit to load as it calculates nearest neighbors to draw the lines between points. I tried to find a better way to reconstruct the mesh from the points, but the surface reconstruction tools in open3d were unsatisfactory and I didn't want to get too dragged down into the weeds there. If I cared more about performance it would probably have to use something like quadtrees. To get it to a reasonable state I balanced the output dimension of the autoencoder (which also increases the time it takes UMAP to run), which is how I got 1024 as a nice power of 2 that is also enough particles to get a sense of the structure. 

The visualization comes with a few controls beyond rotating with the mouse and zooming. Pressing space pauses the animation, and \[ and \] manually changes the frame. This project has led me to see the process of the activation of a transformer as occuring over what I call "layer-time". That is to say, each layer represents a stepwise non-linear transformation of the hidden state, as we might get from measuring the state of a system like Winfree was studying. While my visualization doesn't show any scroll waves, I believe there is some way to reveal an equivalent playing out over the 30 or so layers of the model, that will shed light on the physics of meaning. 
